{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стандартні бібліотеки\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "# Зовнішні бібліотеки\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.layers import Add, Conv2D\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset, zoomed_inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TensorFlow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Доступні GPU: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "cropped_width = 498\n",
    "cropped_height = 300\n",
    "upscale_factor = 3\n",
    "\n",
    "input_width = cropped_width // upscale_factor\n",
    "input_height = cropped_height  // upscale_factor\n",
    "\n",
    "TEST_FOLDER_PATH  = 'D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\images\\\\test'\n",
    "TRAIN_FOLDER_PATH = 'D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\images\\\\train'\n",
    "VAL_FOLDER_PATH   = 'D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\images\\\\val'\n",
    "\n",
    "RAW_TEST_FOLDER_PATH  = 'D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\raw_images\\\\test'\n",
    "RAW_TRAIN_FOLDER_PATH = 'D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\raw_images\\\\train'\n",
    "RAW_VAL_FOLDER_PATH   = 'D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\raw_images\\\\val'\n",
    "\n",
    "TEST_FOLDER_PATH  = '/teamspace/studios/this_studio/Bachelor_thesis/code/data/image/test'\n",
    "TRAIN_FOLDER_PATH = '/teamspace/studios/this_studio/Bachelor_thesis/code/data/image/train'\n",
    "VAL_FOLDER_PATH   = '/teamspace/studios/this_studio/Bachelor_thesis/code/data/image/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Тестовий набір даних:')\n",
    "test_set = image_dataset_from_directory(TEST_FOLDER_PATH, image_size=(cropped_width, cropped_height),\n",
    "                                        batch_size=64, label_mode=None)\n",
    "print(f'\\nНавчальний набір даних:')\n",
    "train_set = image_dataset_from_directory(TRAIN_FOLDER_PATH, image_size=(cropped_width, cropped_height),\n",
    "                                         batch_size=64, label_mode=None)\n",
    "print(f'\\nВалідаційний набір даних:')\n",
    "val_set = image_dataset_from_directory(VAL_FOLDER_PATH, image_size=(cropped_width, cropped_height),\n",
    "                                       batch_size=64, label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(input_image):\n",
    "    input_image = input_image / 255.0\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.map(scaling)\n",
    "train_set = train_set.map(scaling)\n",
    "val_set = val_set.map(scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for batch in train_set.take(1):\n",
    "    for img in batch:\n",
    "        if counter < 3:\n",
    "            display(array_to_img(img))\n",
    "            counter += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(input, new_width, new_height):\n",
    "    input = tf.image.rgb_to_yuv(input)\n",
    "    last_axis = len(input.shape) -1\n",
    "    y, u, v = tf.split(input, 3, axis=last_axis)\n",
    "    return tf.image.resize(y, [new_width, new_height], method=\"area\")\n",
    "\n",
    "\n",
    "def process_target(input):\n",
    "    input = tf.image.rgb_to_yuv(input)\n",
    "    last_axis = len(input.shape) -1\n",
    "    y, u, v = tf.split(input, 3, axis=last_axis)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.map(lambda x: (process_features(x, input_width, input_height),process_target(x)))\n",
    "train_set = train_set.map(lambda x: (process_features(x, input_width, input_height),process_target(x)))\n",
    "val_set = val_set.map(lambda x: (process_features(x, input_width, input_height),process_target(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for batch in train_set.take(1):\n",
    "    for img_lr, img_hr in zip(batch[0], batch[1]):\n",
    "        if counter < 3:\n",
    "            _fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(array_to_img(img_lr), cmap='gray')\n",
    "            ax[0].set_title('Low resolution')\n",
    "            ax[1].imshow(array_to_img(img_hr), cmap='gray')\n",
    "            ax[1].set_title('High resolution')\n",
    "            plt.show()\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdb_block(inputs, numLayers):\n",
    "    \n",
    "    channels = inputs.get_shape()[-1]      # Get the amount of channels in our data, which is 1.\n",
    "    \n",
    "    storedOutputs = [inputs]\n",
    "    \n",
    "    for _ in range(numLayers):             # Here, \"numLayers\" represents the number of Conv2D layers\n",
    "                                           # that are used for the RDB feature extraction process.\n",
    "        localConcat = tf.concat(storedOutputs, axis=-1)\n",
    "        \n",
    "        out = Conv2D(filters=channels, kernel_size=3, padding=\"same\",\n",
    "            activation=\"sigmoid\")(localConcat)\n",
    "        \n",
    "        storedOutputs.append(out)               # The outputs of each Conv2D layer are appended.\n",
    "        \n",
    "    finalConcat = tf.concat(storedOutputs, axis=-1)\n",
    "    finalOut = Conv2D(filters=channels, kernel_size=1,    # This Conv2D layer is called \"pointwise\"\n",
    "        padding=\"same\", activation=\"sigmoid\")(finalConcat)   # convolution layer. It basically prepares\n",
    "                                                          # the data to be added to the original input\n",
    "    finalOut = Add()([finalOut, inputs])                  # and exit the RDB block to enter the next\n",
    "                                                          # layer in the CNN.\n",
    "    return finalOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(channels, upscale_factor):\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    X = Conv2D(64, 5, padding='same', activation='sigmoid', kernel_initializer='Orthogonal')(inputs)\n",
    "    X = Conv2D(64, 3, padding='same', activation='sigmoid', kernel_initializer='Orthogonal')(X)\n",
    "    X = rdb_block(X, numLayers=3)\n",
    "    X = Conv2D(32, 3, padding='same', activation='sigmoid', kernel_initializer='Orthogonal')(X)\n",
    "    X = rdb_block(X, numLayers=3)\n",
    "    X = Conv2D(channels * (upscale_factor**2), 3, padding='same', activation='sigmoid', kernel_initializer='Orthogonal')(X)\n",
    "    \n",
    "    outputs = tf.nn.depth_to_space(X, upscale_factor)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001)\n",
    "model = Model(channels, upscale_factor)        \n",
    "                                               # Adam optimizer due to its efficiency, MSE\n",
    "model.compile(optimizer='adam', loss='MSE')    # loss function because it's a regression model.\n",
    "\n",
    "model.summary()                                # Show a summary of the layers in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint('RDB_Sigmoid_best.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "csv_logger = CSVLogger('training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set, epochs=500, callbacks= [early_stopping], validation_data = val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RDB_Sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RDB_Sigmoid.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('RDB_Sigmoid_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
